{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 7 : classification de textes (pour la désambiguïsation lexicale)\n",
    "Nathan Gonzalez Montes & Guidoux Vincent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif et plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’objectif de ce laboratoire est d’utiliser des méthodes d’apprentissage supervisé pour classifier des occurrences du mot interest selon leur sens : c’est la même tâche, avec les mêmes données, que le labo 6. Pour classifier les occurrences, on considère leur contexte (mots voisins), et on applique l’approche bayésienne vue en cours : on entraîne un classifieur à six classes (les six sens de interest annotés de 1 à 6) sur une partie des données et on le teste sur la partie restante.\n",
    "\n",
    "Dans ce laboratoire, on explore deux façons différentes de coder les traits (features) pour cette tâche. Dans les deux cas, on entraînera un NaiveBayesClassifier fourni par NLTK.1 Les deux façons sont :\n",
    "1. Constituer un vocabulaire des mots qui apparaissent dans le voisinage de interest et définir ces mots comme traits. Pour chaque occurrence de interest, on extrait la valeur de ces traits sous la forme `{(‘rate’ : True), (‘in’ : False), … }` et on ajoute la classe (de 1 à 6).\n",
    "2. Si word-1 est le mot précédant l’occurrence de interest, on définit comme traits word-n, …, word-2, word-1, word+1, word+2, …, word+n (une fenêtre de taille 2n autour de interest). Les valeurs possibles de ces traits sont cette fois-ci les mots observés, ou ‘NONE’ si la fenêtre dépasse les limites de la phrase. Pour chaque occurrence de interest, on extrait la valeur de ces traits sous la forme `{(‘word-1’ : ‘his’), (‘word+1’ : ‘in’), … }` et on ajoute la classe (de 1 à 6).\n",
    "\n",
    "Dans les deux cas, il faut diviser les 2368 occurrences de interest en un jeu d’entraînement et un jeu de test, en respectant la proportion initiale de chaque sens. Puis on entraîne un classifieur bayésien naïf en respectant le format de données indiqué par NLTK2, et on teste la performance du classifieur entraîné. L’objectif est de trouver les paramètres qui conduisent aux meilleurs scores de WSD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste des noms propres, ponctuation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords_dlc = [\"'\", \"''\", \"'s\", '(', ')', '*interest', '*interests', ',', ':', ';', 'At least one of the passed list is empty',\n",
    " 'USsr','``', 'addwest', 'allianz', 'amoco', 'angell', 'angevine', 'anheuser', 'artra', 'avedisian', 'bancorp',\n",
    " 'bankamerica', 'bankshares', 'bavaria', 'beghin', 'bentsen', 'bernhard', 'berson', 'beyer', 'birnbaum', 'bnl', 'bolduc', 'bsn',\n",
    " 'buckley', 'bundesbank', 'caldor',  'campeau',  'canfor',  'cathay',  'cirino',  'citic',  'citicorp',  'citiesabc', 'comsat', 'conagra', 'curragh', 'daimler',\n",
    " 'datatimes', 'dingell', 'doman', 'dougherty', 'drexel','drg', 'ecpa', 'eiji', 'elsinore', 'erc', 'ericson', 'ernst', 'esop', 'esso',\n",
    " 'eubank', 'fasb', 'fii', 'geoffrey', 'giorgio', 'goloven', 'goodson', 'gorbachev', 'gosbank', 'grafil', 'harcourt', 'harriet',\n",
    " 'hca', 'healthvest', 'heyden', 'hirsch', 'honeywell', 'hornbeck', 'icahn', 'interlake', 'itel', 'itoh', 'jerrold', 'kalmus',\n",
    " 'kampen','kaneb', 'kangyo', 'kenyon', 'keogh', 'kerkorian', 'kikkoman', 'kissinger', 'klauser', 'kochan', 'krause', 'laidlaw',\n",
    " 'lazar', 'lbo', 'lbos', 'leaseway', 'leber', 'lipper', 'lipsky', 'lipstein', 'lomas', 'lpl', 'makro', 'malizia', 'massey',\n",
    " 'matra', 'matuschka', 'maxus', 'mccall', 'mccaw', 'mclennan', 'mcorp', 'meritor', 'metromedia', 'mikulich', 'milacron', 'milford', 'milken',\n",
    " 'minorco', 'mitsui', 'mixte', 'mulford', 'nasd', 'ncnb', 'negus', 'nepalese', 'newfoundland', 'nippon', 'nobrega', 'northrop',\n",
    " 'nrm','nyu', \"o'malley\", 'oakes', 'osborne', 'painewebber', 'panamanian', 'pantera', 'papandreou', 'parkos', 'paxus', 'pnc',\n",
    " 'poehl', 'quotron', 'racal', 'rapanelli', 'raytheon', 'refcorp', 'revco', 'richfield', 'rjr', 'rockwell', 'rostenkowski',\n",
    " 'rtc', 'ruiz', 'saatchi', 'sallie', 'salomon', 'sandner', 'satoshi', 'schlossberg', 'schlumberger', 'searby', 'seife', 'shapiro',\n",
    " 'silbert', 'sirrine', 'skase', 'smithkline', 'sotheby', 'sperandeo', 'spiotto', 'steinberg', 'swissair', 'sybase', 'takamori',\n",
    " 'takeshi', 'tci', 'telerate', 'textron', 'thermedics', 'tomsho', 'transco', 'trecker', 'tva', 'uic', 'unilever', 'unisys', 'unocal',\n",
    " 'viacom', 'vickers', 'viyella', 'vuitton', 'waigel', 'weinroth', 'westinghouse', 'weyerhaeuser', 'wisner', 'wyse', 'yeres', 'younkers',\n",
    " 'yukio', 'zurich', '}', '\\'why', '*interested', 'At least one of the passed list is empty', 'MGMNP', '\\\\\\\\*', 'aganbegyan', 'aloys',\n",
    " 'alpert','altimari', 'altman', 'ameritas', 'anctil', 'ankeny', 'anlage', 'arby', 'asarco', 'atb', 'atwood', 'avdel', 'aviva',\n",
    " 'balfour', 'bateman','bddp', 'berardi', 'berbera', 'bianchi', 'biondi', 'birkel', 'blandings', 'bloomingdale', 'bloomingdales',\n",
    " 'blumenfeld', 'bodner','bolar', 'borden', 'boskin', 'braitman', 'bramah', 'brasilia', 'briscoe', 'burbank', 'burnham', 'burrill',\n",
    " 'bynoe', 'cafferarelli', 'cambria', 'capel', 'cashin', 'chandross', 'ciminero', 'comerica', 'congolese', 'conlon', 'corbehem',\n",
    " 'cowles', 'crandall', 'crss', 'daberko', 'daiwa', 'darman', 'depcreciation', 'dimitris', 'dlj', 'donaldson', 'donoghue', 'dorrance', 'doughnut',\n",
    " 'dresdner', 'dreyer', 'edelson', 'elbaum', 'etr', 'farmington', 'faulding', 'fedders', 'ferranti', 'fio', 'firstsouth',\n",
    " 'franyo', 'fulbright', 'fyffes', 'gaubert', 'gec', 'gintel', 'goodison', 'goodwin', 'gould', 'gramm', 'grubman', 'gutermann',\n",
    " 'hammersmith', 'hanwa', 'hartzog', 'hawley', 'hbj', 'heilman', 'hennessey', 'hering', 'hibernia', 'holliston', 'howson',\n",
    " 'hubbell', 'hyman', 'iberian', 'ikegai','intan', 'iras', 'itagaki', 'janson', 'jennison', 'jmb', 'jolla', 'jujo', 'kakita',\n",
    " 'kansan', 'kenji', 'kirkland', 'kohlberg', 'kondo', 'koskotas', 'krauss', 'kuala', 'kulani', 'landini', 'lawrenceville',\n",
    " 'lawrenson', 'lazard', 'lebow', 'lengwin', 'leningrad', 'leventhal', 'levine', 'levinson', 'levitt', 'lidgerwood', 'lightstone',\n",
    " 'lintas', 'liro', 'lockheed', 'lorenzo', 'ludcke', 'lufthansa', 'lupo', 'lustgarten', 'lyphomed', 'mackenzie', 'maclean', 'malato',\n",
    " 'mandle', 'matsuda', 'mcdermott','mcgraw', 'mckusick', 'mehl', 'menem', 'merksamer', 'merritt', 'messaggero', 'mgmua', 'minincomputer',\n",
    " 'minpeco', 'mitsuoka', 'mnb', 'monieson', 'morningstar', 'murata', 'mvestment', 'nakazato', 'natwest', 'newsedge', 'nisshin',\n",
    " 'nzi', \"o'neill\", 'olivetti', 'orgotein', 'ormat', 'packwood', 'pamour', 'parsow', 'pemberton', 'perlman', 'phelan', 'pocklington', 'pomicino', 'pountain',\n",
    " 'prapas', 'prentice','primerit', 'qintex', 'quadrum', 'rainman', 'ralphs', 'recommendatons', 'redford', 'repsol', 'resler',\n",
    " 'rodale', 'rosen', 'rothschild','roulac', 'ruderman', 'ruskin', 'sabre', 'sakowitz', 'salerno', 'sanyo', 'savaiko', 'schering',\n",
    " 'schumer', 'scowcroft', 'seabrook', 'seiders', 'seidman', 'shearson', 'sheraton', 'shirer', 'southbrook', 'sovran', 'squibb',\n",
    " 'stenholm', 'stevric', 'straszheim', 'sumita', 'superconcentrated', 'sykes', 'taft', 'telemunchen', 'terrizzi', 'tietmeyer',\n",
    " 'trelleborg', 'tvsm', 'tvx', 'upham', 'vargas', 'viag', 'visx', 'wachtel', 'waterhouse', 'weissman', 'whitaker', 'whitehall',\n",
    " 'whittaker', 'wyss', 'zoete', '{',  \"'goodison\", \"'who\", 'At least one of the passed list is empty', '\\\\\\\\*', 'algraphy',\n",
    " 'alsthom', 'alun', 'anschluss', 'bache', 'baer', 'banxquote', 'bischofberger', 'caci', \"d'amiante\", 'economidis', 'eichler', 'eiffel','entergy',\n",
    " 'eurobelge', 'exploracion', 'feldemuehle', 'ferruzzi', 'freres', 'galbraith', 'gmb', 'goldwyn', 'hutchinson', 'jaworski', 'jerrico',\n",
    " 'jvcvictor', 'kokusai', 'kravis', 'leval', 'llosa', 'lufkin', 'lumpur', 'maclaine', 'maffei', 'matsushita', 'mca', 'moleculon',\n",
    " 'neiman', 'normura', 'ocn', 'plough', 'proudfoot', 'puna', 'rudman', 'seger', 'sigoloff', 'sithe', 'stateswest', 'swasey','syncor',\n",
    " 'synthetical', 'takashimaya', 'taunton','treausry', 'trupin', 'utsunomiya', 'warburg', 'wedd', 'wyo', 'yellowknife',\n",
    " \"At least one of the passed list is empty\", '\\\\\\\\*', 'bradstreet', 'economdis', 'forstmann', 'heileman', 'lorimar', 'luxembourg', 'pamorex',\n",
    " 'saks', 'turben', 'wassily', '\\\\\\\\*', 'leontief', 'rauscher', 'telepictures', 'interest_', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étapes proposées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Traits lexicaux : présence ou absence de mots dans le voisinage de interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Le fichier de données se trouve à http://www.d.umn.edu/~tpederse/data.html – chercher « interest » vers la fin de la page, et prendre le fichier marqué comme « original format without POS tags » (le même qu’au labo 6). Lire le fichier et générer une liste de listes de mots (une liste par phrase) appelée `tokenized_sentences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'data/interest-original.txt' \n",
    "\n",
    "try:  \n",
    "    fp = open(filepath, 'r',encoding=\"utf-8\")\n",
    "    raw_sentences = fp.read().replace('=', '')\n",
    "    raw_sentences = raw_sentences.replace(',', '')\n",
    "    raw_sentences = raw_sentences.replace('.', '')\n",
    "    raw_sentences = raw_sentences.replace('`', '')\n",
    "    raw_sentences = raw_sentences.replace('\\'', '')\n",
    "    raw_sentences = raw_sentences.split('\\n$$\\n')\n",
    "finally:  \n",
    "    fp.close()\n",
    "    \n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in raw_sentences[:-1]]\n",
    "\n",
    "len(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Définir une variable `window_size`, par exemple égale à 3 (on la fera varier plus tard), et une liste vide de mots `word_list`. Parcourir les `tokenized_sentences` et pour chaque phrase ajouter les mots voisins de interest (i.e. situés à une distance inférieure ou égale à `window_size`) dans la liste de mots `word_list`. Combien de mots contient celle-ci à la fin ? Tokens ou types ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_size = 3\n",
    "\n",
    "word_dict = {1: [], 2: [], 3: [], 4: [], 5: [], 6: []}\n",
    "\n",
    "for sentence in (tokenized_sentences):  \n",
    "    i = None\n",
    "    current_sens = None\n",
    "    for def_i in range(1,7):\n",
    "        current_sens = def_i\n",
    "        if \"interest_{}\".format(def_i) in sentence:\n",
    "            i = sentence.index(\"interest_{}\".format(def_i))\n",
    "            break\n",
    "        elif \"interests_{}\".format(def_i) in sentence:\n",
    "            i = sentence.index(\"interests_{}\".format(def_i))\n",
    "            break\n",
    "    for index in range(-windows_size, windows_size+1):\n",
    "        current_index = index + i\n",
    "        if current_index > 0 and current_index < len(sentence) and index != 0:\n",
    "            word_dict[current_sens].append(sentence[current_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_list 1 : 1951\n",
      "word_list 2 : 65\n",
      "word_list 3 : 309\n",
      "word_list 4 : 933\n",
      "word_list 5 : 2773\n",
      "word_list 6 : 6759\n"
     ]
    }
   ],
   "source": [
    "somme = 0\n",
    "\n",
    "vocabulary = set()\n",
    "word_list = []\n",
    "\n",
    "for i in range(1,7):\n",
    "    number_of_point = 0\n",
    "    current_list = word_dict[i]\n",
    "    print(\"word_list {} : {}\".format(i, len(current_list)))\n",
    "    somme += len(current_list)\n",
    "    for word in current_list:\n",
    "        vocabulary.add(word)\n",
    "        word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre total d'occurances : 12790\n",
      "nombre de mots différents : 2479\n"
     ]
    }
   ],
   "source": [
    "print(\"nombre total d'occurances : {}\".format(somme))\n",
    "print(\"nombre de mots différents : {}\".format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. À l’aide d’un objet `NLTK` de type `FreqDist`, sélectionner parmi les mots de `word_list` les `N` plus fréquents, dans une nouvelle liste appelée `vocabulary` (p.ex. `N = 500`, mais on le fera varier). Affichez les 50 mots les plus fréquents. Est-ce une bonne idée d’enlever les stopwords ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "vocabulary = nltk.FreqDist(word_list).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 762),\n",
       " ('rates', 624),\n",
       " ('the', 606),\n",
       " ('and', 401),\n",
       " ('to', 373),\n",
       " ('of', 330),\n",
       " ('a', 273),\n",
       " ('on', 170),\n",
       " ('rate', 139),\n",
       " ('s', 136),\n",
       " ('%', 135),\n",
       " ('its', 132),\n",
       " ('payments', 112),\n",
       " ('that', 104),\n",
       " ('are', 102),\n",
       " ('has', 94),\n",
       " ('for', 86),\n",
       " ('with', 83),\n",
       " ('lower', 83),\n",
       " ('an', 81),\n",
       " ('is', 72),\n",
       " ('by', 69),\n",
       " ('have', 68),\n",
       " ('will', 65),\n",
       " ('at', 64),\n",
       " ('high', 63),\n",
       " ('from', 61),\n",
       " ('company', 50),\n",
       " ('their', 48),\n",
       " ('or', 48),\n",
       " ('annual', 48),\n",
       " ('us', 47),\n",
       " ('which', 47),\n",
       " ('short', 47),\n",
       " ('minority', 46),\n",
       " ('foreign', 46),\n",
       " ('said', 43),\n",
       " ('higher', 43),\n",
       " ('as', 42),\n",
       " ('bonds', 42),\n",
       " ('income', 42),\n",
       " ('nt', 41),\n",
       " ('other', 41),\n",
       " ('it', 39),\n",
       " ('pay', 39),\n",
       " ('be', 35),\n",
       " ('below', 35),\n",
       " ('up', 34),\n",
       " ('would', 34),\n",
       " ('because', 33)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(word_list).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Est-ce une bonne idée d’enlever les stopwords ?**\n",
    "> blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Parcourir à nouveau les tokenized_sentences et pour chaque phrase créer un couple (dictionnaire, sens), où le dictionnaire regroupe les traits et leurs valeurs, et le sens est un nombre de 1 à 6 indiquant le sens de interest. Les couples pour toutes les phrases seront rassemblés dans une liste appelée feature_sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': False,\n",
       " 'rates': False,\n",
       " 'the': False,\n",
       " 'and': False,\n",
       " 'to': False,\n",
       " 'of': False,\n",
       " 'a': False,\n",
       " 'on': False,\n",
       " 'rate': False,\n",
       " 's': False,\n",
       " '%': False,\n",
       " 'its': False,\n",
       " 'payments': False,\n",
       " 'that': False,\n",
       " 'are': False,\n",
       " 'has': False,\n",
       " 'for': False,\n",
       " 'with': False,\n",
       " 'lower': False,\n",
       " 'an': False,\n",
       " 'is': False,\n",
       " 'by': False,\n",
       " 'have': False,\n",
       " 'will': False,\n",
       " 'at': False,\n",
       " 'high': False,\n",
       " 'from': False,\n",
       " 'company': False,\n",
       " 'their': False,\n",
       " 'or': False,\n",
       " 'annual': False,\n",
       " 'us': False,\n",
       " 'which': False,\n",
       " 'short': False,\n",
       " 'minority': False,\n",
       " 'foreign': False,\n",
       " 'said': False,\n",
       " 'higher': False,\n",
       " 'as': False,\n",
       " 'bonds': False,\n",
       " 'income': False,\n",
       " 'nt': False,\n",
       " 'other': False,\n",
       " 'it': False,\n",
       " 'pay': False,\n",
       " 'be': False,\n",
       " 'below': False,\n",
       " 'up': False,\n",
       " 'would': False,\n",
       " 'because': False,\n",
       " 'short-term': False,\n",
       " 'was': False,\n",
       " 'buying': False,\n",
       " '$': False,\n",
       " 'also': False,\n",
       " 'pursue': False,\n",
       " 'but': False,\n",
       " 'best': False,\n",
       " 'he': False,\n",
       " 'million': False,\n",
       " 'debt': False,\n",
       " 'some': False,\n",
       " 'expressed': False,\n",
       " 'about': False,\n",
       " 'plus': False,\n",
       " 'accrued': False,\n",
       " 'due': False,\n",
       " 'current': False,\n",
       " 'net': False,\n",
       " 'they': False,\n",
       " 'before': False,\n",
       " 'taxes': False,\n",
       " 'public': False,\n",
       " 'equity': False,\n",
       " 'increase': False,\n",
       " 'rose': False,\n",
       " 'new': False,\n",
       " '--': False,\n",
       " 'payment': False,\n",
       " 'expense': False,\n",
       " 'investor': False,\n",
       " 'his': False,\n",
       " 'than': False,\n",
       " 'were': False,\n",
       " 'year': False,\n",
       " 'principal': False,\n",
       " 'had': False,\n",
       " 'any': False,\n",
       " 'mr': False,\n",
       " 'not': False,\n",
       " 'says': False,\n",
       " 'business': False,\n",
       " 'this': False,\n",
       " 'own': False,\n",
       " 'down': False,\n",
       " 'costs': False,\n",
       " 'rise': False,\n",
       " 'national': False,\n",
       " 'fall': False,\n",
       " 'no': False,\n",
       " 'raise': False,\n",
       " 'decline': False,\n",
       " 'may': False,\n",
       " 'if': False,\n",
       " 'bank': False,\n",
       " 'certain': False,\n",
       " 'oil': False,\n",
       " 'drop': False,\n",
       " 'domestic': False,\n",
       " 'cut': False,\n",
       " 'make': False,\n",
       " 'inflation': False,\n",
       " 'reserve': False,\n",
       " 'could': False,\n",
       " 'much': False,\n",
       " 'been': False,\n",
       " 'uk': False,\n",
       " 'over': False,\n",
       " 'paid': False,\n",
       " 'german': False,\n",
       " 'investors': False,\n",
       " 'more': False,\n",
       " 'only': False,\n",
       " 'among': False,\n",
       " 'last': False,\n",
       " 'corp': False,\n",
       " 'all': False,\n",
       " 'government': False,\n",
       " 'market': False,\n",
       " 'financial': False,\n",
       " 'federal': False,\n",
       " 'controlling': False,\n",
       " '15': False,\n",
       " 'raised': False,\n",
       " 'cash': False,\n",
       " 'japanese': False,\n",
       " ';': False,\n",
       " 'possible': False,\n",
       " 'including': False,\n",
       " 'tax': False,\n",
       " 'changes': False,\n",
       " 'sold': False,\n",
       " 'key': False,\n",
       " 'reduce': False,\n",
       " 'strong': False,\n",
       " 'stocks': False,\n",
       " 'our': False,\n",
       " 'banks': False,\n",
       " 'companies': False,\n",
       " 'earnings': False,\n",
       " 'conflict': False,\n",
       " 'fell': False,\n",
       " 'paying': False,\n",
       " 'loans': False,\n",
       " 'further': False,\n",
       " 'securities': False,\n",
       " 'funds': False,\n",
       " 'those': False,\n",
       " 'bill': False,\n",
       " 'speculation': False,\n",
       " 'rising': False,\n",
       " 'when': False,\n",
       " '10': False,\n",
       " 'open': False,\n",
       " 'price': False,\n",
       " 'depreciation': False,\n",
       " 'expenses': False,\n",
       " 'most': False,\n",
       " 'british': False,\n",
       " 'attracted': False,\n",
       " 'acquiring': False,\n",
       " 'remain': False,\n",
       " 'real': False,\n",
       " 'such': False,\n",
       " 'holding': False,\n",
       " 'shareholders': False,\n",
       " 'move': False,\n",
       " 'long-term': False,\n",
       " 'group': False,\n",
       " '50': False,\n",
       " 'raising': False,\n",
       " 'west': False,\n",
       " 'average': False,\n",
       " 'soon': False,\n",
       " 'increases': False,\n",
       " 'failed': False,\n",
       " 'growing': False,\n",
       " 'making': False,\n",
       " 'general': False,\n",
       " 'stock': False,\n",
       " 'since': False,\n",
       " 'jaguar': False,\n",
       " 'big': False,\n",
       " ':': False,\n",
       " 'after': False,\n",
       " 'low': False,\n",
       " 'personal': False,\n",
       " 'amount': False,\n",
       " 'do': False,\n",
       " 'protect': False,\n",
       " 'sell': False,\n",
       " 'sale': False,\n",
       " 'voting': False,\n",
       " 'property': False,\n",
       " 'acquire': False,\n",
       " 'options': False,\n",
       " 'boost': False,\n",
       " 'bring': False,\n",
       " 'fed': False,\n",
       " 'continue': False,\n",
       " 'margin': False,\n",
       " 'little': False,\n",
       " 'great': False,\n",
       " 'issues': False,\n",
       " 'estate': False,\n",
       " 'generally': False,\n",
       " 'already': False,\n",
       " 'special': False,\n",
       " 'recent': False,\n",
       " 'then': False,\n",
       " 'week': False,\n",
       " 'can': False,\n",
       " 'economy': False,\n",
       " 'allowing': False,\n",
       " 'between': False,\n",
       " '20': False,\n",
       " 'include': False,\n",
       " 'insurance': False,\n",
       " '60': False,\n",
       " 'billion': False,\n",
       " 'wo': False,\n",
       " 'fees': False,\n",
       " 'falling': False,\n",
       " 'dividends': False,\n",
       " 'american': False,\n",
       " 'shown': False,\n",
       " 'corporate': False,\n",
       " 'there': False,\n",
       " 'board': False,\n",
       " ')': False,\n",
       " 'while': False,\n",
       " '&': False,\n",
       " 'protecting': False,\n",
       " 'economic': False,\n",
       " 'let': False,\n",
       " '1': False,\n",
       " 'gas': False,\n",
       " 'number': False,\n",
       " 'working': False,\n",
       " 'position': False,\n",
       " 'majority': False,\n",
       " 'primarily': False,\n",
       " 'where': False,\n",
       " 'reduced': False,\n",
       " 'cost': False,\n",
       " 'margins': False,\n",
       " 'now': False,\n",
       " 'international': False,\n",
       " 'showed': False,\n",
       " 'generated': False,\n",
       " 'so': False,\n",
       " 'expressions': False,\n",
       " 'institutional': False,\n",
       " 'lack': False,\n",
       " 'soviet': False,\n",
       " 'consumer': False,\n",
       " 'back': False,\n",
       " 'shares': False,\n",
       " 'against': False,\n",
       " 'one': False,\n",
       " 'takeover': False,\n",
       " 'keeping': False,\n",
       " 'traders': False,\n",
       " 'coming': False,\n",
       " 'less': False,\n",
       " 'time': False,\n",
       " 'acquired': False,\n",
       " 'conflicts': False,\n",
       " 'set': False,\n",
       " 'represent': False,\n",
       " 'policy': False,\n",
       " 'allow': False,\n",
       " '1989': False,\n",
       " 'half': False,\n",
       " 'brewing': False,\n",
       " 'profit': False,\n",
       " 'otc': False,\n",
       " 'month': False,\n",
       " 'cellular': False,\n",
       " 'supply': False,\n",
       " 'concern': False,\n",
       " 'currently': False,\n",
       " 'exchange': False,\n",
       " 'base': False,\n",
       " 'par': False,\n",
       " 'until': False,\n",
       " 'money': False,\n",
       " 'caused': False,\n",
       " 'lowering': False,\n",
       " 'bundesbank': False,\n",
       " 'meet': False,\n",
       " 'again': False,\n",
       " 'small': False,\n",
       " 'remained': False,\n",
       " 'mortgage': False,\n",
       " 'unlikely': False,\n",
       " 'first': False,\n",
       " 'substantial': False,\n",
       " 'especially': False,\n",
       " 'though': False,\n",
       " 'later': False,\n",
       " 'european': False,\n",
       " 'helped': False,\n",
       " 'lost': False,\n",
       " 'limited': False,\n",
       " 'two': False,\n",
       " 'many': False,\n",
       " 'renewed': False,\n",
       " 'express': False,\n",
       " 'very': False,\n",
       " 'customers': False,\n",
       " 'might': False,\n",
       " 'still': False,\n",
       " 'gains': False,\n",
       " 'europe': False,\n",
       " 'who': False,\n",
       " 'western': False,\n",
       " 'businesses': False,\n",
       " 'additional': False,\n",
       " 'expected': False,\n",
       " 'notes': False,\n",
       " 'selling': False,\n",
       " 'continued': False,\n",
       " 'ownership': False,\n",
       " 'increased': False,\n",
       " 'family': False,\n",
       " 'inc': False,\n",
       " '{': False,\n",
       " 'whose': False,\n",
       " 'three': False,\n",
       " 'should': False,\n",
       " 'consumers': False,\n",
       " 'concerns': False,\n",
       " 'banking': False,\n",
       " 'britain': False,\n",
       " 'represents': False,\n",
       " 'remaining': False,\n",
       " '625': False,\n",
       " 'climbed': False,\n",
       " 'columbia': False,\n",
       " 'obligations': False,\n",
       " '14': False,\n",
       " 'lowered': False,\n",
       " 'sept': False,\n",
       " 'nearly': False,\n",
       " 'likely': False,\n",
       " 'outlook': False,\n",
       " 'charges': False,\n",
       " 'relatively': False,\n",
       " 'years': False,\n",
       " 'missed': False,\n",
       " '(': False,\n",
       " 'ease': False,\n",
       " 'germany': False,\n",
       " 'dollar': False,\n",
       " 'priced': False,\n",
       " 'june': False,\n",
       " 'show': False,\n",
       " 'co': False,\n",
       " 'revive': False,\n",
       " 'despite': False,\n",
       " 'gold': False,\n",
       " 'instead': False,\n",
       " 'metals': False,\n",
       " 'precious': False,\n",
       " 'keen': False,\n",
       " 'received': False,\n",
       " 'declined': False,\n",
       " 'buyers': False,\n",
       " 'parties': False,\n",
       " 'considerable': False,\n",
       " 'through': False,\n",
       " 'lot': False,\n",
       " 'pushed': False,\n",
       " 'stir': False,\n",
       " 'being': False,\n",
       " 'clients': False,\n",
       " 'expect': False,\n",
       " 'never': False,\n",
       " 'taken': False,\n",
       " 'major': False,\n",
       " 'support': False,\n",
       " 'partnership': False,\n",
       " 'local': False,\n",
       " 'stake': False,\n",
       " 'out': False,\n",
       " 'difference': False,\n",
       " 'increasing': False,\n",
       " 'franchise': False,\n",
       " 'bond': False,\n",
       " 'immediate': False,\n",
       " 'both': False,\n",
       " 'enough': False,\n",
       " '}': False,\n",
       " 'magazines': False,\n",
       " 'common': False,\n",
       " 'put': False,\n",
       " 'advantage': False,\n",
       " 'country': False,\n",
       " 'important': False,\n",
       " 'united': False,\n",
       " 'holds': False,\n",
       " 'manufacturing': False,\n",
       " 'extraordinary': False,\n",
       " 'products': False,\n",
       " 'australian': False,\n",
       " 'declining': False,\n",
       " 'prices': False,\n",
       " '25': False,\n",
       " 'nasdaq': False,\n",
       " 'reported': False,\n",
       " 'total': False,\n",
       " 'large': False,\n",
       " 'jumped': False,\n",
       " 'biggest': False,\n",
       " '6': False,\n",
       " 'just': False,\n",
       " 'industrial': False,\n",
       " 'city': False,\n",
       " 'telephone': False,\n",
       " 'electronics': False,\n",
       " 'contract': False,\n",
       " 'least': False,\n",
       " '12': False,\n",
       " 'resulting': False,\n",
       " 'swap': False,\n",
       " 'direction': False,\n",
       " 'coverage': False,\n",
       " 'owed': False,\n",
       " 'loan': False,\n",
       " 'true': False,\n",
       " 'drive': False,\n",
       " 'expects': False,\n",
       " 'made': False,\n",
       " 'must': False,\n",
       " 'losses': False,\n",
       " 'during': False,\n",
       " 'overdue': False,\n",
       " 'unpaid': False,\n",
       " 'fixed': False,\n",
       " 'earned': False,\n",
       " 'serial': False,\n",
       " 'credit': False,\n",
       " 'accruing': False,\n",
       " 'savings': False,\n",
       " 'deductibility': False,\n",
       " 'postpone': False,\n",
       " 'change': False,\n",
       " 'fears': False,\n",
       " 'push': False,\n",
       " 'pushing': False,\n",
       " 'use': False,\n",
       " 'toward': False,\n",
       " 'helping': False,\n",
       " 'attract': False,\n",
       " 'drum': False,\n",
       " 'environment': False,\n",
       " 'under': False,\n",
       " 'g': False,\n",
       " 'congress': False,\n",
       " 'drew': False,\n",
       " 'auto': False,\n",
       " 'absence': False,\n",
       " 'beyond': False,\n",
       " 'cutting': False,\n",
       " 'level': False,\n",
       " 'these': False,\n",
       " 'financing': False,\n",
       " 'maker': False,\n",
       " 'abroad': False,\n",
       " 'well': False,\n",
       " 'sparked': False,\n",
       " 'fresh': False,\n",
       " 'addition': False,\n",
       " 'what': False,\n",
       " 'nation': False,\n",
       " 'did': False,\n",
       " 'growth': False,\n",
       " 'potential': False,\n",
       " 'hotels': False,\n",
       " 'broad': False,\n",
       " 'them': False,\n",
       " 'offers': False,\n",
       " 'prompted': False,\n",
       " 'motor': False,\n",
       " 'ago': False,\n",
       " 'share': False,\n",
       " 'even': False,\n",
       " 'investment': False,\n",
       " 'leave': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictonary = {}\n",
    "\n",
    "for trait in vocabulary:\n",
    "    dictonary[trait[0]] = False\n",
    "dictonary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Prendre modèle sur https://www.nltk.org/book/ch06.html (début du 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Pour le dictionnaire, il faut créer un trait pour chaque mot de vocabulary, et examiner si ce mot est présent dans une fenêtre de taille window_size autour de l’occurrence de interest : si oui, le trait est True, sinon il est False. Par exemple, on aboutit à : {'contains(the)': False, 'contains(,)': True, 'contains(rates)': True, …}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Ajouter aussi le trait ‘word0’ qui note si l’occurrence est interest ou interests (pluriel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Combien d’occurrences pour chaque sens de interest y a-t-il dans feature_sets ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Diviser les données de feature_sets en deux sous-ensembles : l’un comportant 80% des données est le train_set, et l’autre (20%) est le test_set. Attention, il faut respecter deux conditions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Chaque sens doit être présent dans les mêmes proportions dans train_set et dans test_set (donc il faut faire la division de manière séparée pour chaque sens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Mélanger avec shuffle() les occurrences avant de prendre les 80% premières pour le `train_set`et les 20% restantes dans le test_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Entraîner un classifieur de type NaiveBayesClassifier de NLTK sur train_set, puis le tester sur les données de test_set. Quelle est la précision (accuracy) atteinte ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Adapter le code précédent pour effectuer plusieurs divisions des données en train et test (par exemple 10), et calculer la moyenne des scores obtenus. Comment se compare cette moyenne avec votre premier résultat ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Cherchez les meilleurs paramètres pour la taille de la fenêtre (p.ex. 1, 3, 5, 7, 11) et la taille du vocabulaire (50, 100, 200, 500, 1000 mots). Combien d’expériences faut-il exécuter ? Quelle est la meilleure combinaison fenêtre x vocabulaire et quel est le score moyen obtenu ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Traits lexicaux positionnels : valeurs des mots précédant/suivant interest\n",
    "Pour cette deuxième partie, on réutilisera beaucoup d’éléments de la première. Seule la nature des\n",
    "traits utilisés et leur extraction vont changer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Partir de la liste de listes de mots (une liste par phrase) précédente, appelée tokenized_sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Définir une variable window_size2, par exemple égale à 3 (on la fera varier plus tard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Parcourir les tokenized_sentences et pour chaque phrase créer un couple (dictionnaire, sens), où le dictionnaire regroupe les traits et leurs valeurs, et le sens est un nombre de 1 à 6 indiquant le sens de interest. Les couples pour toutes les phrases seront rassemblés dans une nouvelle liste appelée feature_sets2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Pour le dictionnaire de traits, il faut cette fois-ci créer un trait pour chaque position relative par rapport à interest, donc ‘word-1’, ‘word+1’, etc. (jusqu’à window_size2). La valeur du trait sera le mot trouvé à cette position, ou ‘NONE’ si on sort de la phrase. Par exemple {(‘word-1’ : ‘his’), (‘word+1’ : ‘in’), … }."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Ajouter aussi le trait ‘word0’ qui note si l’occurrence est interest ou interests (pluriel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Diviser les données de feature_sets2 en deux sous-ensembles (80%/20%) appelés train_set2 et test_set2 avec la même procédure qu’à la partie A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Entraîner un classifieur de type NaiveBayesClassifier de NLTK sur train_set2, puis le tester sur les données de test_set2. Quelle est la précision (accuracy) atteinte ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Effectuer plusieurs divisions des données en train et test (par exemple 10), et calculer la moyenne des scores obtenus. Comment se compare cette moyenne avec votre premier résultat ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Cherchez les meilleurs paramètres pour la taille de la fenêtre (p.ex. entre 1 et 15). Quelle est la meilleure valeur et quel est le score moyen obtenu ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Quelle est le meilleur score obtenu entre (A) et (B) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Thème de réflexion facultatif : les différences des scores sont-elles statistiquement significatives ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merci d’envoyer votre notebook Jupyter par email au professeur avant le **lundi 27 mai à 23h59**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
